{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# algorithm-efficiency-complexity-asymptotic-analysis-big-O\n",
    "> [TABLE OF CONTENTS](https://github.com/E6985/E2746/blob/master/README.md)\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **notation** - ${0}$ - not zero - 0 - **symbolism** used in - complexity theory - mathematics - computer science - describes the **asymptotic** **behaviours** of **functions** - **measures** how quickly a function will grow or decline - categorise **growth** - also called Landaus symbol after the German number theoretician Edmund Landau who invented the notation - the growth rate of a function is also called its **order** - the capitalised greek letter - omicron - was originally used - has fallen out of favour - capitalised latin letter - ${0}$ - is now commonly used - algoroithm - y - runs in - $O(n^{2})$ - time [6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- computer science - **describe** the **complexity** of an algorithm in the **worst-case** scenario - can be used to describe the execution time required or the space used - eg - in memory or on disk by an algorithm - focusing on execution **time** - number of **operations** required by an algorithm - can be thought of as a **measure** of the expected - **efficiency** - of an algorithm [6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- for any **small** **size** of - x - **all** algorithms are **efficient** - fast enough to be used for real time applications albeit as the size of the **input** **increases** non-trivial - significantly - **order** of growth - big ${0}$ notation - of an algorithm will become more significant - more **important** [6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **evaluating** the **complexity** of algorithms can say that if - big ${0}$ **notations** - are **similar** their complexity in terms of time/space requirements is similar in the worst case - if two algorithms have the **same** - big ${0}$ **notation** - does **not** mean both will **execute** at exactly the same **time** - means that the **order** of the number of **operations** required to complete is the same - algorithm that takes eleven operations to compute versus another algorithm that takes ten operations to compute - both are of the same order of magnitude - algorithm that takes one-hundred operations to compute or another algorithm that takes ten operations to compute - both are of different orders of magnitude therefore have different - big ${0}$ notation - if algorithm - a - has a less complex - big ${0}$ notation - versus algorithm - b - can infer that it is much more efficient in terms of space/time requirements at least in the worst case [6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- two functions - $f(x)$ - $g(x)$ - defined on some subset of a set of real numbers - function - $f(x)$ - expected running time - expected number of operations - function - $g(x)$ - complexity function - could be one the growth functions - logarithmic - linear - linearithmic - polynomial - exponential - function - f - of x - $f(x)$ - equals - ${0}$ - g of x - $O(g(x))$ - as the size of the input set - x - tends towards infinity - function - $f(x)$ - expected running time - expected number of operations - is of the order of - growth function - $g(x)$ - as the size of the input set - x - tends towards infinity as the input set size - x - increases - number of elements - the term in the - function - $O()$ - begins to dominate - if growth function - quadratic - $n^{2}$ - as - x - as the input set size tends towards infinity - then the quadratic term - $n^{2}$ - begins to dominate - if growth function - quadratic - $n^{2}$ - would be the highest order term that is actually in control of how many operations are executed by an algorithm [6]\n",
    "\n",
    "$f(x) = O(g(x))$ for x -> infinity\n",
    "\n",
    "- only under a certain condition - if - only if - there exist constants - $N$ - $C$ - such that the magitude of - function - $f(x)$ - is less than or equal to some constant - function - $g(x)$ - for all input set size - x - greater than - $N$  - intuitively this means that - function - $f(x)$ - does not grow more quickly than function - $g(x)$ - note that - $N$ - is size of the input set which is large enough for the higher order term to begin to dominate [6]\n",
    "\n",
    "$|f(x)| <= C|g(x) |$ for all x > N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- big O notation - aim to **identify** the **tightest** **upper** **bound** for the number of operations when analysing an algorithm - take an algorithm that is known to have a growth function - quadratic - $n^{2}$ - big **${0}$** notation - $O(n^{2})$ - highest order term is the square of the number of elements that is input - **term** becomes to **dominate** - expected running time - expected number of operations - $O(n^{2})$ - in the worst case - executes in - $O(n^{2})$ - time - also executes in - $O(n^{3})$ - time - correct to determine this algorithm is also - $O(n^{3})$ - definition - $O(n^{2})$ - more useful - there is a large difference in the expected running time - expected number of operations between - $O(n^{3})$ algorithm - versus - $O(n^{2})$ algorithm - better to identify the tightest upper bound possible on - expected running time - expected number of operations - real world - specifying an upper bound which is higher - slack evident - than that is necessary is like saying - task will take at most one week to complete - when in reality the true maximum time - expected running time - expected number of operations - five minutes - depending on how complex the set of inputs or conditions imposed - correct to say the task will take a maximum of five minutes - also correct to say it will take a maximum of one week or less than one week - analogy - difference between - $O(n^{2})$ - $O(n^{3})$ - if the tightest upper bound as possible can be identified - more useful when analysing algorithms - **deciding** which **algorithm** to use in a **specific** problem **instance** [6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
